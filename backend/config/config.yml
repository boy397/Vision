# ── App ──
app:
  name: "Vision Assistive System"
  default_mode: "medical"
  trigger: "voice"
  fps: 10
  language: "en"
  debug: false

# ── Detection (Tier 1 - defaults, overridden per mode) ──
detection:
  model: "yolo26n"
  confidence: 0.45
  device: "cuda"
  input_size: 640
  quantized: true
  state_change_threshold: 0.3

# ── Modes (per-mode model + detection overrides) ──
modes:
  medical:
    detection:
      model: "yolo26n"
      confidence: 0.40
      classes: ["pill_bottle", "blister_pack", "medicine_box", "prescription"]
    llm:
      provider: "groq"
      model: "llama-3.2-11b-vision-preview"
    prompt_file: "prompts/medical.yml"
  retail:
    detection:
      model: "yolo26n"
      confidence: 0.40
      classes: []  # Empty = detect ALL objects (general object detection)
    llm:
      provider: "groq"
      model: "llama-3.2-11b-vision-preview"
    prompt_file: "prompts/retail.yml"

# ── LLM Provider (Tier 2 Vision + Chat) ──
# Each provider has a `model` (active) and `available_models` (selectable from UI).
# To add a new model, just append it to available_models — the frontend picks it up automatically.
llm:
  provider: "groq"  # Options: google | groq | azure | vllm
  groq:
    model: "llama-3.2-11b-vision-preview"
    temperature: 0.3
    max_tokens: 512
    available_models:
      - id: "llama-3.2-11b-vision-preview"
        name: "Llama 3.2 11B Vision"
        description: "Fast & lightweight vision"
        vision: true
      - id: "meta-llama/llama-4-scout-17b-16e-instruct"
        name: "Llama 4 Scout 17B"
        description: "Latest Llama 4 scout model"
        vision: true
      - id: "meta-llama/llama-4-maverick-17b-128e-instruct"
        name: "Llama 4 Maverick 17B"
        description: "Latest Llama 4 maverick model"
        vision: true
      - id: "moonshotai/kimi-k2-instruct-0905"
        name: "Kimi K2 Instruct"
        description: "Moonshot AI reasoning model"
        vision: false
  google:
    model: "gemini-2.0-flash"
    temperature: 0.3
    max_tokens: 512
    stream: true
    available_models:
      - id: "gemini-2.0-flash"
        name: "Gemini 2.0 Flash"
        description: "Fast multimodal"
        vision: true
      - id: "gemini-2.5-flash-preview-05-20"
        name: "Gemini 2.5 Flash"
        description: "Latest flash model"
        vision: true
      - id: "gemini-2.5-pro-preview-05-06"
        name: "Gemini 2.5 Pro"
        description: "Best quality, slower"
        vision: true
  azure:
    model: "gpt-4o"
    api_version: "2024-12-01-preview"
    temperature: 0.3
    max_tokens: 512
    available_models:
      - id: "gpt-4o"
        name: "GPT-4o"
        description: "OpenAI multimodal"
        vision: true
      - id: "gpt-4o-mini"
        name: "GPT-4o Mini"
        description: "Fast & cheap"
        vision: true
  vllm:
    model: "Qwen/Qwen2.5-VL-7B-Instruct"
    api_base: "http://localhost:8001/v1"
    temperature: 0.3
    max_tokens: 512
    available_models:
      - id: "Qwen/Qwen2.5-VL-7B-Instruct"
        name: "Qwen 2.5 VL 7B"
        description: "Local vision model"
        vision: true

# ── STT (Speech-to-Text) ──
stt:
  provider: "sarvam"
  google:
    model: "latest_long"
    language: "en-IN"
  sarvam:
    model: "saarika:v2.5"      # REST API model (legacy /voice/listen fallback)
    language: "en-IN"          # Use "unknown" for auto-detect, "hi-IN" for Hindi
    streaming_model: "saaras:v3"    # WebSocket streaming model (new /voice/sarvam)
    streaming_mode: "transcribe"    # transcribe | translate | verbatim | codemix | translit

# ── TTS (Text-to-Speech) ──
tts:
  provider: "sarvam"  # Switch to "elevenlabs" to use ElevenLabs instead
  elevenlabs:
    voice_id: "JBFqnCBsd6RMkjVDRZzb"
    model: "eleven_turbo_v2_5"
    stability: 0.5
    similarity_boost: 0.75
    stream: true
  sarvam:
    model: "bulbul:v3"
    language: "en-IN"
    speaker: "shubh"  # Must be lowercase. v3 speakers: shubh, aditya, ritu, priya, neha, rahul, pooja, rohan, simran, kavya...

# ── Voice Commands ──
voice:
  vad_aggressiveness: 2
  wake_word_enabled: false
  silence_timeout_ms: 800

# ── Server ──
server:
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["*"]
